# Default configuration for the LLM From Scratch project

# Model parameters
model:
  model_type: 'gpt'
  vocab_size: 50257
  d_model: 768
  num_heads: 12
  num_layers: 12
  d_ff: 3072
  max_seq_length: 512
  dropout: 0.1

# Tokenizer parameters
tokenizer:
  tokenizer_type: 'bpe'
  tokenizer_path: 'tokenizers/bpe_gpt2_small.json'

# Data parameters
data:
  dataset: 'wikitext' # 'wikitext' or 'text_files'
  data_dir: 'data'
  text_files_dir: null # Specify path if using 'text_files'

# Training parameters
training:
  batch_size: 16
  learning_rate: 0.0001
  max_epochs: 3 # A small default, can be overridden for longer runs
  checkpoint_dir: 'checkpoints/gpt_medium_local'
  device: null # 'cuda', 'mps', 'cpu', or null for auto-detection
  resume: null # Path to a checkpoint to resume from

# Generation parameters
generation:
  generate: false # Set to true to run in generation mode
  prompt: 'The secret to happiness is'
  max_length: 100
  temperature: 0.7 